<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.3">Jekyll</generator><link href="https://www.lindstromhenrik.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.lindstromhenrik.com/" rel="alternate" type="text/html" /><updated>2018-06-21T14:11:29+02:00</updated><id>https://www.lindstromhenrik.com/</id><title type="html">a life in search</title><subtitle></subtitle><author><name>Henrik Lindström</name></author><entry><title type="html">Facet filtering with EPiServer Find</title><link href="https://www.lindstromhenrik.com/facet-filtering-with-episerver-find/" rel="alternate" type="text/html" title="Facet filtering with EPiServer Find" /><published>2016-06-02T00:00:00+02:00</published><updated>2016-06-02T00:00:00+02:00</updated><id>https://www.lindstromhenrik.com/facet-filtering-with-episerver-find</id><content type="html" xml:base="https://www.lindstromhenrik.com/facet-filtering-with-episerver-find/">&lt;p&gt;&lt;span&gt;Sometimes you want to have a facet calculated on just a subset of the result or have multiple facets each being calculated on a different subset of the result. To enable this I’ve created a small extension project to the Episerver Find API, &lt;a href=&quot;https://github.com/x2find/FacetFilter2Find&quot;&gt;FacetFilter2Find&lt;/a&gt;, that enables passing a filter to TermsFacetFor(…) that will filter the result set when calculating the facet.&lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;How to use the FacetFilter2Find extension&lt;/h2&gt;

&lt;p&gt;&lt;span&gt;To use it you simply pass a filter when requesting the facet:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
result = client.Search&amp;lt;Document&amp;gt;()
                        .TermsFacetFor(x =&amp;gt; x.Category, x =&amp;gt; x.Type.Match(&quot;pdf&quot;))
                        .GetResult();
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;and fetch the resulting facet:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
facet = result.TermsFacetFor(x =&amp;gt; x.Category);
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;In order to specify multiple facets on a single field, each having a different filter, one must specify a custom name:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
result = client.Search&amp;lt;Document&amp;gt;()
                        .TermsFacetFor(x =&amp;gt; x.Category, x =&amp;gt; x.Type.Match(&quot;pdf&quot;), x =&amp;gt; x.Name = &quot;PdfCategories&quot;)
                        .TermsFacetFor(x =&amp;gt; x.Category, x =&amp;gt; x.Type.Match(&quot;doc&quot;), x =&amp;gt; x.Name = &quot;DocCategories&quot;)
                        .GetResult();
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;and fetch the resulting facets:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
pdfTypeFacet = result.Facets[&quot;PdfCategories&quot;] as TermsFacet;
docTypeFacet = result.Facets[&quot;DocCategories&quot;] as TermsFacet;
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;I hope you may find this useful when making your site awesome with EPiServer Find!&lt;/span&gt;&lt;/p&gt;</content><author><name>Henrik Lindström</name></author><category term="EPiServer" /><category term="EPiServer.Find" /><summary type="html">Sometimes you want to have a facet calculated on just a subset of the result or have multiple facets each being calculated on a different subset of the result...</summary></entry><entry><title type="html">Integration tests with Protractor</title><link href="https://www.lindstromhenrik.com/integration-tests-with-protractor/" rel="alternate" type="text/html" title="Integration tests with Protractor" /><published>2014-05-21T00:00:00+02:00</published><updated>2014-05-21T00:00:00+02:00</updated><id>https://www.lindstromhenrik.com/integration-tests-with-protractor</id><content type="html" xml:base="https://www.lindstromhenrik.com/integration-tests-with-protractor/">&lt;p&gt;&lt;span&gt;After playing around with Protractor for a while I wanted to create some integration tests where I would bootstrap the entire server/database before each test to get a consistent state to start from in each test. The problem is that we often have to wait for everything to setup before running the tests. Using Jasmine as test framework the obvious solution for this would be to use the async callback in &lt;strong&gt;beforeEach&lt;/strong&gt; do something like:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
beforeEach((done) -&amp;gt;
    server.start(() -&amp;gt;
        done()
    )
)
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;and &lt;strong&gt;server.start&lt;/strong&gt;:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
start = (done) -&amp;gt;
    server = spawn('coffee', [ 'server.coffee' ])
    server.stdout.on('data', (data) -&amp;gt;
        if data.toString() == 'App started\n'
            done()
    )
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Simply put, the server spawns a new process that starts our server using the command: &lt;strong&gt;‘coffee server.coffee’&lt;/strong&gt; and then listen to stdout for the log output &lt;strong&gt;‘App started\n’&lt;/strong&gt; and then issues the callback &lt;strong&gt;done&lt;/strong&gt; (this is of course purely an example).&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;The problem is that Protractor overrides the async callback in &lt;strong&gt;beforeEach&lt;/strong&gt; and never waits for our server to actually start. The reason is that Protractor helps you with handling all the async calls of WebdriverJS and creates its own &lt;a href=&quot;https://github.com/angular/protractor/blob/master/docs/control-flow.md&quot;&gt;control flow&lt;/a&gt; using &lt;a href=&quot;https://github.com/kriskowal/q&quot;&gt;promises&lt;/a&gt; that overrides Jasmines async callback. Instead of using the Jasmine async callback we need to make the &lt;strong&gt;server.start&lt;/strong&gt; return a &lt;strong&gt;promise&lt;/strong&gt; and then add that to the Protractor control flow.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;First we need to import &lt;strong&gt;q&lt;/strong&gt; (the Promise module) into our project using:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
npm install q
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Then we modify our &lt;strong&gt;server.start&lt;/strong&gt; to return a promise instead of using the callback:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
Q = require('q')

start = () -&amp;gt;
    deferred = Q.defer()
    server = spawn('coffee', [ 'server.coffee' ])
    server.stdout.on('data', (data) -&amp;gt;
        if data.toString() == 'App started\n'
            deferred.resolve()
    )

    return deferred.promise
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Finally we add that to the Protractor control flow in the &lt;strong&gt;beforeEach&lt;/strong&gt; function:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
beforeEach(() -&amp;gt;
    protractor.promise.controlFlow().execute(() -&amp;gt;
        return server.start()
    )
)
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Voila! Now Protractor waits for our server to actually start before continuing with running the tests. Using this approach we can create integration tests that bootstraps the server before each test and completely isolates tests from each other enabling us to create better test scenarios that don’t depend on what order the tests are runned.&lt;/span&gt;&lt;/p&gt;</content><author><name>Henrik Lindström</name></author><category term="angularjs" /><category term="testing" /><summary type="html">After playing around with Protractor for a while I wanted to create some integration tests where I would bootstrap the entire server/database before each test to get a consistent state to start from in each test. The problem is that we often have to wait for everything to be setup before running the tests...</summary></entry><entry><title type="html">Using Protractor with CoffeeScript</title><link href="https://www.lindstromhenrik.com/using-protractor-with-coffescript/" rel="alternate" type="text/html" title="Using Protractor with CoffeeScript" /><published>2014-05-12T00:00:00+02:00</published><updated>2014-05-12T00:00:00+02:00</updated><id>https://www.lindstromhenrik.com/using-protractor-with-coffescript</id><content type="html" xml:base="https://www.lindstromhenrik.com/using-protractor-with-coffescript/">&lt;p&gt;&lt;span&gt;I’ve been playing around with AngularJS  for the last couple of weeks during my spare time while being on paternity leave (read: late at night). I really like the framework and last night I came across Protractor, the end to end testing framework, and for the first time I think I saw some light in the the UI-testing-tunnel and thought I should share some ideas in a couple of posts. First I’ll start with how to use Protractor with CoffeScript and how to get a nice fluent syntax in your testing scenarios (thanks to &lt;a href=&quot;https://github.com/angular/protractor/issues/275#issuecomment-29106082&quot;&gt;cyranix&lt;/a&gt; for getting me inspired).&lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;Using Protractor with CoffeeScript&lt;/h2&gt;

&lt;p&gt;&lt;span&gt;I like using CoffeScript (even though I’m kind of verbose when I use it compared to most as I like keeping the parentheses) and thought it would be great if I could write my Page Objects as CoffeScript classes and chain the functions giving me a fluent syntax like:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
startPage.
    .clickLogin()
            .setUserName('john.doe@acme.com')
            .setPassword('donttellanyone')
            .submit()
    browser.waitForAngular()
    
    expect(browser.getLocationAbsUrl()).toMatch('/app/#!/dashboard')
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;So, how do we do this? First we need to register CoffeScript in the protractor configuration to be able to use it in our scenarios:&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;protractor-conf.js&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
exports.config = {
    allScriptsTimeout: 11000,

    specs: [
        'e2e/*.scenarios.coffee'
    ],

    capabilities: {
        'browserName': 'chrome'
    },

    baseUrl: 'http://localhost:10000/app',

    framework: 'jasmine',

    jasmineNodeOpts: {
        defaultTimeoutInterval: 30000
    }
};
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Note: If you don’t have CoffeScript installed grab it with:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;npm install coffee-script&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Next we need to create our Page Objects and we will start with the &lt;strong&gt;start page&lt;/strong&gt;:&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;start_page.coffee&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
LoginPage = require('./login_page')

class StartPage
    constructor: -&amp;gt;
        @loginLink = element(By.id('loginLink'))

    get: -&amp;gt;
        browser.get('app/#!/')
        return @

    clickLogin: -&amp;gt;
        @loginLink.click()
        browser.waitForAngular()
        return new LoginPage()

module.exports = StartPage
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;We grab the login link element in the constructor (I’ve just set the id in the html view so that it is easy to get hold of in the tests and making the test a bit more robust if I decide to move the login link). When someone then clicks login we click the link and wait for angular to complete the request and then we return the Page Object for the &lt;strong&gt;login page&lt;/strong&gt;.&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;The Page Object for the &lt;strong&gt;login page&lt;/strong&gt; looks similar in structure but have a username and password field that the user can fill out (Here I use the &lt;strong&gt;By.model&lt;/strong&gt; to get hold of the input fields for the username and password. Also note that I use return @ to return &lt;strong&gt;this&lt;/strong&gt; in the functions to make it chainable):&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;login_page.coffee&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
LoginPage = require('./login_page')

class LoginPage
    constructor: -&amp;gt;
        @username = element(By.model('user.name'))
        @password = element(By.model('user.password'))
        @loginButton = element(By.id('loginButton'))
        @errorMessage = element(By.id('loginErrorMessage'))

    get: -&amp;gt;
        browser.get('app/#!/auth/login')
        return @

    getErrorMessage: -&amp;gt;
        return @errorMessage.getText()

    setUserName: (text) -&amp;gt;
        @username.sendKeys(text)
        return @

    clearUserName: -&amp;gt;
        @username.clear()
        return @

    setPassword: (text) -&amp;gt;
        @password.sendKeys(text)
        return @

    clearPassword: -&amp;gt;
        @password.clear()
        return @

    submit: -&amp;gt;
        @loginButton.click()

module.exports = LoginPage
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Now we can simply &lt;strong&gt;require&lt;/strong&gt; the &lt;strong&gt;start page&lt;/strong&gt; Page Object in our scenarios to get the fluent syntax in our testing scenario:&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;login.scenarios.coffee&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
StartPage = require('../PageObjects/start_page')

describe('&lt;e2e&gt;', () -&amp;gt;
    loginPage = null

    beforeEach(() -&amp;gt;
        startPage = new StartPage()
        startPage.get()
        loginPage = startPage.clickLogin()
    )

    describe('login', () -&amp;gt;
        it('should login and redirect to the dashboard with valid user credentials', () -&amp;gt;
            loginPage
                .setUserName('john.doe@acme.com')
                .setPassword('donttellanyone')
                .submit()
            browser.waitForAngular()
            
            expect(browser.getLocationAbsUrl()).toMatch('/app/#!/dashboard')
        )

...more tests
}
&amp;lt;/pre&amp;gt;

&lt;span&gt;This way we get a nice structure and a pretty neat fluent syntax in our testing scenarios. Next up is how to bootstrap your server/database before each test scenario so that you can make integration test scenarios from a consistent state every time. I'll get back to that in a future post.&lt;/span&gt;


&lt;/e2e&gt;&lt;/pre&gt;</content><author><name>Henrik Lindström</name></author><category term="angularjs" /><category term="testing" /><summary type="html">I’ve been playing around with AngularJS for the last couple of weeks during my spare time while being on paternity leave (read late at night). I really like the framework and last night I came across Protractor, the end to end testing framework, and for the first time I think I saw some light in the the UI-testing-tunnel and thought I should share some ideas in a couple of posts...</summary></entry><entry><title type="html">Language detection using Elasticsearch</title><link href="https://www.lindstromhenrik.com/language-detection-using-elasticsearch/" rel="alternate" type="text/html" title="Language detection using Elasticsearch" /><published>2013-10-30T00:00:00+01:00</published><updated>2013-10-30T00:00:00+01:00</updated><id>https://www.lindstromhenrik.com/language-detection-using-elasticsearch</id><content type="html" xml:base="https://www.lindstromhenrik.com/language-detection-using-elasticsearch/">&lt;p&gt;&lt;span&gt;A couple of weeks ago I had the privilege to speak at the Elasticsearch Meetup in Stockholm where I did show a slightly tweaked version of the ‘language categorizer’ I did write about a couple of months ago and would like to share the changes I did (the naive approach wasn’t  accurate enough to be presented live in public ;-)).&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;First, instead of using the default mapping for the ‘text’ field we use the nGram-tokenizer where we specify that we want to index all 2 and 3 letter ngrams of the text. Every language basically have different frequencies for each letter sequence and we want to find the language not by the words in the query but by how common the letter sequences are (as an example ‘th’ is very common in english but rare in swedish). This way we will actually be able to detect the language for a word sequence even if we haven’t actually seen any of the words in the training set. So, we extend our mappings to use the nGram-tokenizer:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
{
    &quot;settings&quot; : {
        &quot;analysis&quot; : {
            &quot;analyzer&quot; : {
                &quot;ngram_analyzer&quot; : {
                    &quot;tokenizer&quot; : &quot;ngram_tokenizer&quot;
                }
            },
            &quot;tokenizer&quot; : {
                &quot;ngram_tokenizer&quot; : {
                    &quot;type&quot; : &quot;nGram&quot;,
                    &quot;min_gram&quot; : &quot;2&quot;,
                    &quot;max_gram&quot; : &quot;3&quot;,
                    &quot;token_chars&quot;: [ &quot;letter&quot;, &quot;digit&quot; ]
                }
            }
        }
    },
    &quot;mappings&quot;: {
        &quot;data&quot;: {
            &quot;_parent&quot;: {
                &quot;type&quot;: &quot;category&quot;
            },
            &quot;properties&quot;: {
                &quot;text&quot;: {
                    &quot;type&quot;: &quot;string&quot;, 
                    &quot;analyzer&quot;: &quot;ngram_analyzer&quot;                
                }
            }
        }
    }
}
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;When querying we then want to calculate the average score for each language using the has_child query but we don’t want the query to filter out any hits but rather return a 0-score for a document that doesn’t match (i.e. we don’t want the score for one language to be based on maybe one tenth of all documents for that language and the score for another to be based on half of the documents for that language). To do this we use the ‘boosting’ query where we simply give a boost to all documents matching the query:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
{
  &quot;query&quot;:{
    &quot;has_child&quot;: {
      &quot;type&quot;: &quot;data&quot;,
      &quot;score_type&quot; : &quot;avg&quot;,
      &quot;query&quot;: {
        &quot;boosting&quot; : {
            &quot;positive&quot; : {
                &quot;match&quot;: {
                  &quot;text&quot;: &quot;skriver en bok&quot;
                }
            },
            &quot;negative&quot; : {
               &quot;match_all&quot;: { }
            },
            &quot;negative_boost&quot; : 1
        }
    }
    }
  }
}
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Using these simple ‘tweaks’ we have actually created a very accurate language detector. If you want to give it a try you can create training sets from the &lt;a href=&quot;http://corpora.uni-leipzig.de&quot;&gt;Leipzig Corpora Collection&lt;/a&gt; for the different languages you want to detect.&lt;/span&gt;&lt;/p&gt;</content><author><name>Henrik Lindström</name></author><category term="elasticsearch" /><summary type="html">A couple of weeks ago I had the privilege to speak at the Elasticsearch Meetup in Stockholm where I did show a slightly tweaked version of the 'language categorizer' I did write about a couple of months ago and would like to share the changes I did (the naive approach wasn’t accurate enough to be presented live in public ;-))...</summary></entry><entry><title type="html">Indexing only referenced VPP-files with EPiServer Find</title><link href="https://www.lindstromhenrik.com/indexing-only-referenced-vpp-files-with-episerver-find/" rel="alternate" type="text/html" title="Indexing only referenced VPP-files with EPiServer Find" /><published>2013-05-02T00:00:00+02:00</published><updated>2013-05-02T00:00:00+02:00</updated><id>https://www.lindstromhenrik.com/indexing-only-referenced-vpp-files-with-episerver-find</id><content type="html" xml:base="https://www.lindstromhenrik.com/indexing-only-referenced-vpp-files-with-episerver-find/">&lt;p&gt;&lt;span&gt;The EPiServer Find CMS integration does not index any files stored in the VPP by default. A convention is included in the integration that index files visible in the file manager and it is enabled by setting the VisibleInFilemanagerVPPIndexingConvention on the FilieIndexer conventions:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
FileIndexer.Instance.Conventions.ShouldIndexVPPConvention 
  = new VisibleInFilemanagerVPPIndexingConvention();
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;However, this convention can be a little bit aggressive. As soon as an editor adds a file it is searchable and even though no access control mechanism are overruled some might think it is hidden until it is actually used on the site. So how do we proceed to achieve this?&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Built in into the CMS there is the ContentSoftLinkRepository where we can query if files (or any IContent for that matter) is linked from within another IContent. By using this we can then create a file indexing convention that checks if the file is linked from some indexed IContent and if so we index it:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
FileIndexer.Instance.Conventions.ForInstancesOf&amp;lt;UnifiedFile&amp;gt;().ShouldIndex(x =&amp;gt;
{
    var contentRepository = 
        ServiceLocation.ServiceLocator.Current.GetInstance&amp;lt;IContentRepository&amp;gt;();
    var contentSoftLinkRepository = 
        ServiceLocation.ServiceLocator.Current.GetInstance&amp;lt;ContentSoftLinkRepository&amp;gt;();
    var softLinks = contentSoftLinkRepository.Load(x.VirtualPath);

    try
    {
        foreach (var softLink in softLinks)
        {
            
            if (softLink.SoftLinkType == ReferenceType.ExternalReference ||
                softLink.SoftLinkType == ReferenceType.ImageReference)
            {
                var content = 
                    contentRepository.Get&amp;lt;IContent&amp;gt;(softLink.OwnerContentLink);
                if (!ContentIndexer.Instance.Conventions.ShouldIndexConvention.ShouldIndex(content).Value) // don't index referenced file if content is marked as not indexed
                {
                    continue;
                }

                // only index if content is published
                var publicationStatus = 
                    content.PublishedInLanguage()[softLink.OwnerLanguage.Name];

                if (publicationStatus != null &amp;amp;&amp;amp;
                    (publicationStatus.StartPublish == null ||
                     publicationStatus.StartPublish &amp;lt; DateTime.Now) &amp;amp;&amp;amp;
                    (publicationStatus.StopPublish == null ||
                     DateTime.Now &amp;lt; publicationStatus.StopPublish))
                {
                    return true;
                }
            }
        }
    }
    catch
    {
        // ooops something went wrong. Better not index this one ;-)
    }

    return false;
});
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Using this convention only files that are referenced from an indexed IContent, that also is published (as by default also unpublished IContent is indexed to provide better querying in editor mode).&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;I hope you may find this useful when making your site awesome with EPiServer Find!&lt;/span&gt;&lt;/p&gt;</content><author><name>Henrik Lindström</name></author><category term="EPiServer" /><category term="EPiServer.Find" /><summary type="html">The EPiServer Find CMS integration does not index any files stored in the VPP by default. A convention is included in the integration that index files visible in the file manager and it is enabled by setting the VisibleInFilemanagerVPPIndexingConvention on the FilieIndexer conventions...</summary></entry><entry><title type="html">Nested filtering with EPiServer Find</title><link href="https://www.lindstromhenrik.com/nested-filtering-with-episerver-find/" rel="alternate" type="text/html" title="Nested filtering with EPiServer Find" /><published>2013-03-15T00:00:00+01:00</published><updated>2013-03-15T00:00:00+01:00</updated><id>https://www.lindstromhenrik.com/nested-filtering-with-episerver-find</id><content type="html" xml:base="https://www.lindstromhenrik.com/nested-filtering-with-episerver-find/">&lt;p&gt;&lt;span&gt;Some have already noticed one of the x2find mebers, &lt;a href=&quot;https://github.com/x2find/Nested2Find&quot;&gt;Nested2Find&lt;/a&gt;, that enables nested object mappings and filtering to the EPiServer Find API. I would like to give a short description of what it does and how it can help you in some filtering scenarios.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Sometimes we need to be able to filter documents based on matching a specific object in a lists of complex objects on the document. Say for instance that we have documents that have a list of all authors that have contributed. Authors that all have a set of properties such as name and address. We then want to find all documents where one of the authors match a specific set of criterias, say all documents that have a swedish author named Henrik. This is what Nested2Find enables you to do. It lets you define nested lists of complex objects on a document for which you then later can specify a matching criteria when querying.&lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;How to use the Nested2Find extension&lt;/h2&gt;

&lt;p&gt;&lt;span&gt;Add the nested conventions to the conventions:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
client.Conventions.AddNestedConventions();
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Create an object containing a NestedList&amp;lt;&amp;gt; of objects (NestedList&amp;lt;&amp;gt; is simply a typed List&amp;lt;&amp;gt;):&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
public class Document
{
    public Document()
    {
        Authors = new NestedList&amp;lt;Author&amp;gt;();
    }
    public string Title { get; set; }
    public NestedList&amp;lt;Author&amp;gt; Authors { get; set; }
    public string Body { get; set; }
}

public class Author
{
    public string Name { get; set; }
    public string Address { get; set; }
    public string Country { get; set; }
}
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Index and start filtering:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
result = client.Search&amp;lt;Document&amp;gt;()
             .Filter(x =&amp;gt; x.Authors, p =&amp;gt; p.Name.Match(&quot;Henrik&quot;) &amp;amp; p.Country.Match(&quot;Sweden&quot;))
             .GetResult();
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;or:&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
result = client.Search&amp;lt;Document&amp;gt;()
            .Filter(x =&amp;gt; x.Authors.MatchItem(p =&amp;gt; p.FirstName.Match(&quot;Henrik&quot;) &amp;amp; p.Country.Match(&quot;Sweden&quot;)))
            .GetResult();
&lt;/pre&gt;

&lt;sapn&gt;I hope you may find this useful when making your site awesome with EPiServer Find!&amp;lt;/span&amp;gt;
&lt;/sapn&gt;</content><author><name>Henrik Lindström</name></author><category term="EPiServer" /><category term="EPiServer.Find" /><summary type="html">Some have already noticed one of the x2find mebers, Nested2Find, that enables nested object mappings and filtering to the EPiServer Find API. I would like to give a short description of what it does and how it can help you in some filtering scenarios...</summary></entry><entry><title type="html">Categorizing using Elasticsearch</title><link href="https://www.lindstromhenrik.com/categorizing-using-elasticsearch/" rel="alternate" type="text/html" title="Categorizing using Elasticsearch" /><published>2013-03-08T00:00:00+01:00</published><updated>2013-03-08T00:00:00+01:00</updated><id>https://www.lindstromhenrik.com/categorizing-using-elasticsearch</id><content type="html" xml:base="https://www.lindstromhenrik.com/categorizing-using-elasticsearch/">&lt;p&gt;&lt;span&gt;I’m fortunate to work at a company that once a month have a ‘hack day’ when we are allowed to just try out new and crazy ideas. As an advocate of using search for so much more than just the ‘search page’ I decided to do a small demo of how to use Elasticsearch to do categorization and I wanted to share some of my ideas.&lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;The approach&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;We often have a large amount of data that we know falls into different categories and that we can use as a sample space for predicting unseen data. If we index all this data that we have and look at the unseen data as ‘queries’ we should be able to construct queries where the score when querying the known data space represent a similarity between the ‘objects’. However, now that we have a result where each ‘object’ in the result has a similarity score with the ‘queried’ object how should we interpret it? What if we group all items in the results by each category that we know that they fall into and then calculate the avg similarity score within that group and return the category for which the avg score is the highest? Depending on your data and problem space constructing the similarity query might be more or less easy but the beauty of this approach is that is very easy to implement in Elasticsearch using parent-child mappings.&lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;Demo: Implementing a language categorizer&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;We start by creating an index (I’ve named it ‘myindex’) and add a parent mapping between a category type and a data type:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
http://localhost:9200/myindex
{
    &quot;mappings&quot;: {
        &quot;data&quot;: {
            &quot;_parent&quot;: {
                &quot;type&quot;: &quot;category&quot;
            }
        }
    }
}
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Then we add the known categories:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
http://localhost:9200/myindex/category/sv
{
    &quot;name&quot;: &quot;Swedish&quot;
}
...
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;For the ‘known’ data we index it and relate it to the parent category:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
http://localhost:9200/myindex/data/1?parent=sv
{
    &quot;text&quot;: &quot;det här är en text skriven på svenska&quot;
}
...
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Using the has_child-query we can then easily achieve the described approach of searching for categories and have them returned based on the avg score of a child-query issued on the data. (In this case we just do a simple query_string-query with the text we want do do language detection for, ‘en svensk text’):&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
http://localhost:9200/myindex/category/_search
{
  &quot;query&quot;:{
    &quot;has_child&quot;: {
      &quot;type&quot;: &quot;data&quot;,
      &quot;score_type&quot; : &quot;avg&quot;,
      &quot;query&quot; : {
        &quot;query_string&quot;: {
          &quot;query&quot;: &quot;en svensk text&quot;
        }
      }
    }
  }
}
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Resulting in:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
{
    &quot;took&quot;: 27,
    &quot;timed_out&quot;: false,
    &quot;_shards&quot;: {
        &quot;total&quot;: 5,
        &quot;successful&quot;: 5,
        &quot;failed&quot;: 0
    },
    &quot;hits&quot;: {
        &quot;total&quot;: 1,
        &quot;max_score&quot;: 0.3125,
        &quot;hits&quot;: [
            {
                &quot;_index&quot;: &quot;myindex&quot;,
                &quot;_type&quot;: &quot;category&quot;,
                &quot;_id&quot;: &quot;sv&quot;,
                &quot;_score&quot;: 0.3125,
                &quot;_source&quot;: {
                    &quot;name&quot;: &quot;Swedish&quot;
                }
            }
        ]
    }
}
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Voila! In just 4 steps you know have your very own language detector.&lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;Discussion&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;The described language detector might be a bit simplistic but can easily be more advanced by adding more advanced analyzers for your indexed data using stemmers or alike for the appropriate language. However the approach can be tweaked to do much more advanced queries on more complex objects using all the fancy query types available in Elasticsearch (just ignore the ConstantScore-query ;-)). Only your imagination stops you from creating appropriate similarity queries that might give you really good results in just a few easy steps!&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;So stop looking at your ‘search engine’ as a search page provider and see it as a great tool for not just querying but also a great source for analyzing your data!&lt;/span&gt;&lt;/p&gt;

&lt;h3&gt;Note:&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;The Elasticsearch0.20.x releases have a bug in the has_child-query calculating the sum and not the avg score when using the score_type=avg. I’ve issued a &lt;a href=&quot;https://github.com/elasticsearch/elasticsearch/pull/2747&quot;&gt;pull request&lt;/a&gt; but if you want to try it out you can clone and build from the master branch where the upgraded Lucene distribution circumvents the problem.&lt;/span&gt;&lt;/p&gt;</content><author><name>Henrik Lindström</name></author><category term="elasticsearch" /><summary type="html">I'm fortunate to work at a company that once a month have a 'hack day' when we are allowed to just try out new and crazy ideas. As an advocate of using search for so much more than just the 'search page' I decided to do a small demo of how to use Elasticsearch to do categorization and I wanted to share some of my ideas...</summary></entry><entry><title type="html">Hierarchical faceting with EPiServer Find</title><link href="https://www.lindstromhenrik.com/hierarchical-faceting-with-episerver-find/" rel="alternate" type="text/html" title="Hierarchical faceting with EPiServer Find" /><published>2013-02-26T00:00:00+01:00</published><updated>2013-02-26T00:00:00+01:00</updated><id>https://www.lindstromhenrik.com/hierarchical-faceting-with-episerver-find</id><content type="html" xml:base="https://www.lindstromhenrik.com/hierarchical-faceting-with-episerver-find/">&lt;p&gt;&lt;span&gt;A quite common use case for facets is to show a listing of the number of documents in a result for the different categories on the site (quite common is maybe an understatement as this is often the “hello world!” of faceting). A document can occur in maybe one or more categories and this is where your search index really stands out since it doesn’t care if you have one or two categories associated with the document it will return your facet in no time anyway. Sometimes your categories have a hierarchical structure that you want to reflect in your facet. Lets say that you have documents about cars and want to have a category tree based on manufacturer and name, ie. Volvo/XC60. How can you achieve a facet where you get an aggregated count for each level in the category tree? For example:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
Volkswagen (7)
    Passat (5)
    Tiguan (2)
Volvo (10)
    V70 (5)
    V60 (2)
    …
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;The simplest way of doing this is by associating each document with all levels for each of its categories. Then by using a terms facet when fetching your result you will get an aggregated count for each node in your category tree. Voila, there is your hierarchical facet but with just a few lines of code you can get Find to do all that dirty work of your hands and all you have to do is to pass a category string (each level separated by a ‘/’) and return a facet that parse the result and reflects the nested structure of the category tree. I will leave out the implementation details but at &lt;a href=&quot;https://github.com/x2find/HierarchicalFacet2Find&quot;&gt;HierarchicalFacet2Find&lt;/a&gt; you can fetch your own copy of the code that does that work for you.&lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;How to use the HierarchicalFacet2Find extension&lt;/h2&gt;

&lt;p&gt;&lt;span&gt;Add a Hierarchy property to the document:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
public class Document
{
    [Id]
    public string Id { get; set; }

    public Hierarchy Hierarchy { get; set; }
}
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Set the hierarchy path:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
document.Hierarchy = &quot;A/B/C/D&quot;;
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Index and request a HierarchicalFacet when searching:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
result = client.Search&amp;lt;Document&amp;gt;()
            .HierarchicalFacetFor(x =&amp;gt; x.Hierarchy)
            .GetResult();
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Fetch it from the result:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
facet = result.HierarchicalFacetFor(x =&amp;gt; x.Hierarchy)
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;Loop over the nested hierarchy paths:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
foreach(var hierarchyPath in facet)
{
    hierarchyPath.Path;
    hierarchyPath.Count;

    foreach (var subHierarchyPath in hierarchyPath)
    {
        subHierarchyPath.Path;
        subHierarchyPath.Count;
        ...
    }
}
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;I hope you may find this useful when making your site awesome with EPiServer Find!&lt;/span&gt;&lt;/p&gt;</content><author><name>Henrik Lindström</name></author><category term="EPiServer" /><category term="EPiServer.Find" /><summary type="html">A quite common use case of facets is to show a listing of the number of documents in a result for the different categories on the site (quite common is maybe an understatement as this is often the &quot;hello world!&quot; of faceting). A document can occur in maybe one or more categories and this is where your search index really stands out since it doesn’t care if you have one or two categories associated with the document it will return your facet in no time anyway. Sometimes your categories have a hierarchical structure that you want to reflect in your facet...</summary></entry><entry><title type="html">Time to live with EPiServer Find</title><link href="https://www.lindstromhenrik.com/time-to-live-with-episerver-find/" rel="alternate" type="text/html" title="Time to live with EPiServer Find" /><published>2013-02-15T00:00:00+01:00</published><updated>2013-02-15T00:00:00+01:00</updated><id>https://www.lindstromhenrik.com/time-to-live-with-episerver-find</id><content type="html" xml:base="https://www.lindstromhenrik.com/time-to-live-with-episerver-find/">&lt;p&gt;&lt;span&gt;The latest release of EPiServer Find contains, apart for a number of bug fixes, one new feature and that is the ability to set a time to live-value on indexed documents. The value is expressed as a TimeSpan and specifies how long the document should reside in the index before it is automatically deleted. This can be really useful if you index documents continuously (say that you index all items that users currently are looking at on your site) but only what to show the latest (i.e. what users are currently looking at on the site) and don’t want to flood your index over time (i.e I don’t care what someone looked at yesterday). Under these circumstances the time to live-feature can really help you by doing that dirty cleanup job that we all hate to to do.&lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;How to use time to live&lt;/h2&gt;

&lt;p&gt;&lt;span&gt;Given an object with a TimeToLive property (or TimeSpan):&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
public class WithTimeToLive
{
    [Id]
    public string Id { get; set; }

    public TimeToLive TimeToLive { get; set; }
}
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;We first need to configure the client and register the TimeToLive-property for the given object type:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
client.Conventions.ForInstancesOf&amp;lt;WithTimeToLive&amp;gt;()
    .TimeToLiveIs(x =&amp;gt; x.TimeToLive);
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;When indexing an object we simply register a TimeSpan value to the property specifying how long it should reside in the index:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
indexObject = new WithTimeToLive()
    {
        Id = &quot;123&quot;,
        TimeToLive = new TimeSpan(0, 5, 0)
    };
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;I hope you may find this useful when making your site awesome with EPiServer Find!&lt;/span&gt;&lt;/p&gt;

&lt;h3&gt;Note:&lt;/h3&gt;

&lt;p&gt;&lt;span&gt;The granularity of time to live is 60 seconds meaning that the documents will be deleted within 60 seconds of the actual time to live.&lt;/span&gt;&lt;/p&gt;

&lt;h3&gt;Updated:&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;Instead of configuring the TimeToLive-property by the conventions it can be annotated by the TimeToLiveAttribute:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
public class WithTimeToLive
{
    [Id]
    public string Id { get; set; }
    
    [TimeToLive]
    public TimeToLive TimeToLive { get; set; }
}
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;or passed in the index call:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
client.Index(indexObjext, x =&amp;gt; x.TimeToLive = new TimeSpan(0, 5, 0));
&lt;/pre&gt;</content><author><name>Henrik Lindström</name></author><category term="EPiServer" /><category term="EPiServer.Find" /><summary type="html">The latest release of EPiServer Find contains, apart for a number of bug fixes, one new feature and that is the ability to set a time to live value on indexed documents. The value is expressed as a TimeSpan and specifies how long the document should reside in the index before it is automatically deleted. This can be really useful if you index documents continuously (say that you index all items that users currently are looking at on your site) but only what to show the latest (i.e. what users are currently looking at on the site) and don’t want to flood your index over time (i.e I don’t care what someone looked at yesterday). Under these circumstances the time to live-feature can really help you by doing that dirty cleanup job that we all hate to to do...</summary></entry><entry><title type="html">Random sort with EPiServer Find</title><link href="https://www.lindstromhenrik.com/random-sort-with-episerver-find/" rel="alternate" type="text/html" title="Random sort with EPiServer Find" /><published>2013-01-31T00:00:00+01:00</published><updated>2013-01-31T00:00:00+01:00</updated><id>https://www.lindstromhenrik.com/random-sort-with-episerver-find</id><content type="html" xml:base="https://www.lindstromhenrik.com/random-sort-with-episerver-find/">&lt;p&gt;&lt;span&gt;I’ll continue my series of blog posts today based on “questions I’ve got” with one regarding randomly ordered search results. This can be quite useful if you want to show a subset of a search result and expose the individual result items of the entire result set equally. Say that you for instance have a list campaign products and want to show a limited number of these on the front page but still expose each one of them an equal amount of times to the users. To do this we need to extend the EPiServer Find API with script sorting functionality and add an Order-extension to the fluent API that sorts each result item based on a random number generated by the script. At &lt;a href=&quot;https://github.com/x2find/Random2Find&quot;&gt;Random2Find&lt;/a&gt; you can fetch your own copy of the code.&lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;How to use Random2Find&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;Random2Find is a pure query time extension that don’t need to be registered at startup so all you need to do is specifying  OrderRandom on your query:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
client.Search&amp;lt;Document&amp;gt;()
    .OrderRandom()
    .GetResult();
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;OrderRandom can of course also be used in conjunction with another OrderBy-clause if you want to randomly order items within a subset of ordered items:&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;
client.Search&amp;lt;Document&amp;gt;()
    .OrderBy(x =&amp;gt; x.Name)
    .ThenOrderRandom()
    .GetResult();
&lt;/pre&gt;

&lt;p&gt;&lt;span&gt;I hope you may find this useful when making your site awesome with EPiServer Find.&lt;/span&gt;&lt;/p&gt;</content><author><name>Henrik Lindström</name></author><category term="EPiServer" /><category term="EPiServer.Find" /><summary type="html">I’ll continue my series of blog posts today based on “questions I’ve got” with one regarding randomly ordered search results. This can be quite useful if you want to show a subset of a search result and expose the individual result items of the entire result set equally. Say that you for instance have a list campaign products and want to show a limited number of these on the front page but still expose each one of them an equal amount of times to the users...</summary></entry></feed>